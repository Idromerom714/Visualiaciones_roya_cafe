"""
app.py - Dashboard interactivo (Streamlit)
- Seleccionar municipio
- Seleccionar variable clim谩tica / fitosanitaria
- Sugerencias de tipo de gr谩fico por variable
- Mostrar indicador de riesgo (gauge)
- Mostrar mapa de zonas si existe mapa_zonas.py (opcional)
- NUEVO: Mapa de calor de correlaci贸n (Clima vs Riesgo)
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import seaborn as sns
import plotly.graph_objects as go
import importlib.util
import matplotlib.pyplot as plt
import statsmodels.api as sm
from statsmodels.discrete.discrete_model import Logit, NegativeBinomial # Se a帽ade NegativeBinomial

# --- 1. CONFIGURACIN INICIAL Y CARGA DE DATOS ---

st.set_page_config(layout="wide", page_title="Dashboard de Riesgo Clim谩tico del Caf茅")

@st.cache_data
def load_data():
    """Carga y pre-procesa los datos."""
    try:
        df_clima = pd.read_csv("data/clima_ubicaciones.csv")
        df_ubicaciones = pd.read_csv("ubicaciones.csv")
        df_enfermedades = pd.read_csv("data/enfermedades.csv")

        # Limpieza de columnas de clima
        df_clima.columns = ['latitud', 'longitud', 'fecha_hora', 'temperatura', 
                            'humedad_relativa', 'precipitacion', 'radiacion_solar', 'humeda']
        df_clima['fecha_hora'] = pd.to_datetime(df_clima['fecha_hora'])
        
        # Limpieza y tipado en df_ubicaciones
        df_ubicaciones.columns = df_ubicaciones.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.replace('掳C', '')
        # Se asume que el nombre de la columna de altitud es Altitud_m_s_n_m despu茅s de la limpieza
        df_ubicaciones.rename(columns={'Altitud_m_s._n._m': 'Altitud_m_s_n_m'}, inplace=True)
        df_ubicaciones['Altitud_m_s_n_m'] = pd.to_numeric(df_ubicaciones['Altitud_m_s_n_m'], errors='coerce')
        
        df_enfermedades.columns = ['Enfermedad', 'Patogeno_Causante', 'T_min', 'T_max', 'HR_min', 'Frecuencia_Lluvia']
        
        df_merged = pd.merge(df_clima, 
                            df_ubicaciones[['latitud', 'longitud', 'Hacienda', 'Altitud_m_s_n_m']], 
                            on=['latitud', 'longitud'], 
                            how='left')
        
        return df_merged, df_enfermedades, df_ubicaciones

    except FileNotFoundError:
        st.error("Error al cargar los archivos CSV. Aseg煤rate de que los archivos est谩n en el directorio de ejecuci贸n.")
        return None, None, None

df_merged, df_enfermedades, df_ubicaciones = load_data()
umbrales = df_enfermedades.set_index('Enfermedad')

if df_merged is None:
    st.stop()



# --- 2. FUNCIONES DE CLCULO Y SIMULACIN ---

@st.cache_data
def calculate_indicators(df_filtered, umbrales):
    """Calcula NHF y GD para el DataFrame de clima filtrado."""
    
    df_results = df_filtered[['latitud', 'longitud', 'Hacienda']].drop_duplicates()
    
    # --- A. Indicador F煤ngico: Roya (NHF) ---
    T_min_roya = umbrales.loc['Roya del caf茅', 'T_min']
    T_max_roya = umbrales.loc['Roya del caf茅', 'T_max']
    HR_min_roya = umbrales.loc['Roya del caf茅', 'HR_min']

    df_filtered['riesgo_roya'] = (
        (df_filtered['temperatura'] >= T_min_roya) & 
        (df_filtered['temperatura'] <= T_max_roya) & 
        (df_filtered['humedad_relativa'] >= HR_min_roya) & 
        (df_filtered['humeda'] == 1)
    ).astype(int)
    
    nhf_roya = df_filtered.groupby(['latitud', 'longitud', 'Hacienda'])['riesgo_roya'].sum().reset_index()
    df_results = pd.merge(df_results, nhf_roya[['latitud', 'longitud', 'riesgo_roya']], on=['latitud', 'longitud'], how='left')
    df_results.rename(columns={'riesgo_roya': 'NHF_Roya_Horas'}, inplace=True)
    
    # --- B. Indicador de Plaga: Broca (GD) ---
    T_base_broca = umbrales.loc['Broca del caf茅 (Plaga)', 'T_min'] 
    
    df_filtered['gd_hora_broca'] = np.where(
        df_filtered['temperatura'] > T_base_broca,
        (df_filtered['temperatura'] - T_base_broca) / 24,
        0
    )
    
    gd_broca = df_filtered.groupby(['latitud', 'longitud', 'Hacienda'])['gd_hora_broca'].sum().reset_index()
    df_results = pd.merge(df_results, gd_broca[['latitud', 'longitud', 'gd_hora_broca']], on=['latitud', 'longitud'], how='left')
    df_results.rename(columns={'gd_hora_broca': 'GD_Broca_Acumulado'}, inplace=True)
    
    # Merge Altitud para el an谩lisis de correlaci贸n y modelo
    df_results = pd.merge(df_results, df_ubicaciones[['latitud', 'longitud', 'Altitud_m_s_n_m']], 
                         on=['latitud', 'longitud'], how='left')

    return df_results


def simulate_incidence(df_indicators):
    """Simula datos binarios de incidencia de Roya basados en NHF y Altitud."""
    np.random.seed(42) 
    # Asegurar que no hay NaNs y crear Altitud en km
    df_indicators['Altitud_km'] = df_indicators['Altitud_m_s_n_m'].fillna(0) / 1000
    df_indicators['NHF_Roya_Horas'] = df_indicators['NHF_Roya_Horas'].fillna(0)

    # Modelo: logit(P) = -3.0 + 0.05*NHF - 1.5*Altitud_km
    linear_predictor = -3.0 + (0.05 * df_indicators['NHF_Roya_Horas']) - (1.5 * df_indicators['Altitud_km'])
    probability = 1 / (1 + np.exp(-linear_predictor))

    # Clip para garantizar valores v谩lidos en [0,1]
    probability = np.clip(probability, 0.0, 1.0)

    # np.random.binomial acepta p como array; pasar solo p (sin size) cuando p es vector
    try:
        simulated = np.random.binomial(n=1, p=probability)
    except Exception:
        # Fallback: usar probabilidad escalar promedio si algo falla
        p_scalar = float(np.nan_to_num(probability.mean(), nan=0.0))
        simulated = np.random.binomial(n=1, p=p_scalar, size=len(df_indicators))

    df_indicators['Incidencia_Roya_Simulada'] = simulated

    return df_indicators

def simulate_count(df_indicators):
    """Simula datos de conteo (N煤mero de Brocas) basados en GD y Altitud."""
    np.random.seed(43) 
    # Asegurar que no hay NaNs y crear Altitud en km
    df_indicators['Altitud_km'] = df_indicators['Altitud_m_s_n_m'].fillna(0) / 1000
    df_indicators['GD_Broca_Acumulado'] = df_indicators['GD_Broca_Acumulado'].fillna(0)

    # Modelo: log(lambda) = 1.0 + 0.1*GD - 0.8*Altitud_km
    linear_predictor_log = 1.0 + (0.1 * df_indicators['GD_Broca_Acumulado']) - (0.8 * df_indicators['Altitud_km'])
    lambda_mean = np.exp(linear_predictor_log)

    # Garantizar valores v谩lidos para lambda (no negativos, no NaN)
    lambda_mean = np.nan_to_num(lambda_mean, nan=0.0)
    lambda_mean = np.clip(lambda_mean, 0.0, None)

    # Convertir a numpy array y generar conteos por elemento
    lam_array = np.asarray(lambda_mean)
    try:
        simulated_counts = np.random.poisson(lam=lam_array)
    except Exception:
        # Fallback: usar media escalar si la generaci贸n por elemento falla
        lam_scalar = float(np.mean(lam_array)) if len(lam_array) > 0 else 0.0
        simulated_counts = np.random.poisson(lam=lam_scalar, size=len(df_indicators))

    df_indicators['Conteo_Broca_Simulada'] = simulated_counts

    return df_indicators

def run_logistic_regression(df_model):
    """Ejecuta un modelo de Regresi贸n Log铆stica (Logit) y devuelve el resumen."""
    df_model = df_model.dropna(subset=['NHF_Roya_Horas', 'Altitud_km', 'Incidencia_Roya_Simulada'])
    if df_model.empty: return "Error: Datos insuficientes despu茅s de la limpieza."
    
    Y = df_model['Incidencia_Roya_Simulada']
    X = df_model[['NHF_Roya_Horas', 'Altitud_km']]
    X = sm.add_constant(X, prepend=False)
    
    try:
        model = Logit(Y, X)
        result = model.fit(disp=False)
        return result
    except Exception as e:
        return f"Error al ejecutar el modelo Log铆stico: {e}"

def run_negative_binomial(df_model):
    """Ejecuta un modelo de Regresi贸n Binomial Negativa."""
    df_model = df_model.dropna(subset=['GD_Broca_Acumulado', 'Altitud_km', 'Conteo_Broca_Simulada'])
    if df_model.empty: return "Error: Datos insuficientes despu茅s de la limpieza."

    Y = df_model['Conteo_Broca_Simulada']
    X = df_model[['GD_Broca_Acumulado', 'Altitud_km']]
    X = sm.add_constant(X, prepend=False)
    
    try:
        model = NegativeBinomial(Y, X)
        result = model.fit(disp=False)
        return result
    except Exception as e:
        return f"Error al ejecutar el modelo Binomial Negativo: {e}"


# --- 3. DISEO DEL DASHBOARD ---

st.title(" Dashboard de Indicadores de Riesgo Clim谩tico del Caf茅")
st.markdown("Herramienta para evaluar el riesgo de pat贸genos seg煤n variables clim谩ticas hist贸ricas.")

# --- BARRA LATERAL DE FILTROS ---
st.sidebar.header("Filtros de An谩lisis")

# A. Filtro de Ubicaciones
unique_haciendas = df_merged['Hacienda'].unique().tolist()
selected_haciendas = st.sidebar.multiselect(
    "1. Seleccionar Ubicaciones",
    options=unique_haciendas,
    default=unique_haciendas[0] 
)

# B. Filtro de Pat贸geno
patogeno_options = {
    'Roya del caf茅 (NHF)': 'NHF_Roya_Horas',
    'Broca del caf茅 (GD)': 'GD_Broca_Acumulado'
}
selected_patogeno_name = st.sidebar.selectbox(
    "2. Seleccionar Pat贸geno/Indicador",
    options=list(patogeno_options.keys())
)
selected_indicator_col = patogeno_options[selected_patogeno_name]

# C. Filtro de Rango de Fechas
min_date = df_merged['fecha_hora'].min().date()
max_date = df_merged['fecha_hora'].max().date()

date_range = st.sidebar.date_input(
    "3. Seleccionar Rango de Fechas",
    value=(min_date, max_date),
    min_value=min_date,
    max_value=max_date
)

# Aplicar filtro de fecha y ubicaci贸n
if len(date_range) == 2:
    start_date = pd.to_datetime(date_range[0])
    end_date = pd.to_datetime(date_range[1]) + pd.Timedelta(days=1)
    
    df_filtered_date = df_merged[
        (df_merged['fecha_hora'] >= start_date) & 
        (df_merged['fecha_hora'] < end_date)
    ]
    df_filtered_final = df_filtered_date[df_filtered_date['Hacienda'].isin(selected_haciendas)].copy()
else:
    st.warning("Selecciona un rango completo de fechas para el an谩lisis.")
    st.stop()
    
# Recalcular Indicadores con los datos filtrados
df_indicators = calculate_indicators(df_filtered_final, umbrales)

# Simular la incidencia/conteo basado en la selecci贸n del usuario
if selected_patogeno_name == 'Roya del caf茅 (NHF)':
    df_indicators = simulate_incidence(df_indicators) 
elif selected_patogeno_name == 'Broca del caf茅 (GD)':
    df_indicators = simulate_count(df_indicators) 


# --- SECCIN DE INDICADORES (KPIs) ---

st.header(f"Resultados Agregados para {selected_patogeno_name}")
col1, col2, col3 = st.columns(3)

max_risk = df_indicators[selected_indicator_col].max()
col1.metric(
    label=f"M谩ximo Riesgo ({selected_indicator_col.split('_')[0]})", 
    value=f"{max_risk:,.2f}"
)

avg_risk = df_indicators[selected_indicator_col].mean()
col2.metric(
    label=f"Promedio de Riesgo", 
    value=f"{avg_risk:,.2f}"
)

max_risk_location = df_indicators.loc[df_indicators[selected_indicator_col].idxmax(), 'Hacienda']
col3.metric(
    label="Ubicaci贸n m谩s Afectada", 
    value=max_risk_location
)

st.divider()

# --- SECCIN DE GRFICOS ---

st.header("An谩lisis de Tendencia y Distribuci贸n")

# Gr谩fico A: Tendencia de la variable clim谩tica principal
if selected_patogeno_name == 'Roya del caf茅 (NHF)':
    df_daily_temp = df_filtered_final.groupby([df_filtered_final['fecha_hora'].dt.date, 'Hacienda'])['temperatura'].mean().reset_index()
    fig_line = px.line(
        df_daily_temp, 
        x='fecha_hora', 
        y='temperatura', 
        color='Hacienda', 
        title='Temperatura Promedio Diaria vs. Umbrales de Roya (18-25掳C)'
    )
    fig_line.add_hrect(y0=18, y1=25, line_width=0, fillcolor="red", opacity=0.1, annotation_text="Rango ptimo Roya")
    st.plotly_chart(fig_line, use_container_width=True)

elif selected_patogeno_name == 'Broca del caf茅 (GD)':
    # Asegurarse de que la columna 'gd_hora_broca' existe (si no, calcularla localmente)
    df_temp = df_filtered_final.copy()
    if 'gd_hora_broca' not in df_temp.columns:
        try:
            T_base_broca = umbrales.loc['Broca del caf茅 (Plaga)', 'T_min']
        except Exception:
            T_base_broca = 20  # valor por defecto si no se encuentra en umbrales

        df_temp['gd_hora_broca'] = np.where(
            df_temp['temperatura'] > T_base_broca,
            (df_temp['temperatura'] - T_base_broca) / 24,
            0
        )

    df_daily_gd = df_temp.groupby([df_temp['fecha_hora'].dt.date, 'Hacienda'])['gd_hora_broca'].sum().reset_index()
    df_daily_gd.rename(columns={'fecha_hora': 'date', 'gd_hora_broca': 'gd_hora_broca'}, inplace=True)
    df_daily_gd['GD_Acumulado'] = df_daily_gd.groupby('Hacienda')['gd_hora_broca'].cumsum()

    fig_cum = px.line(
        df_daily_gd, 
        x='date', 
        y='GD_Acumulado', 
        color='Hacienda', 
        title='Acumulaci贸n de Grados-D铆a (GD) para Broca'
    )
    st.plotly_chart(fig_cum, use_container_width=True)

# Gr谩fico B: Ranking del Indicador
fig_bar = px.bar(
    df_indicators.sort_values(selected_indicator_col, ascending=False), 
    x='Hacienda', 
    y=selected_indicator_col, 
    color='Altitud_m_s_n_m', 
    title=f"Ranking de Riesgo por Ubicaci贸n ({selected_indicator_col})",
    color_continuous_scale=px.colors.sequential.Sunset,
    hover_data=['Altitud_m_s_n_m']
)
st.plotly_chart(fig_bar, use_container_width=True)


# --- 4. MATRIZ DE CORRELACIN ---

st.header("Correlaci贸n de Riesgo y Variables Clim谩ticas")
st.markdown(f"Matriz de correlaci贸n de **{selected_indicator_col}** con las variables ambientales agregadas por ubicaci贸n.")

# 1. Preparar DataFrame de correlaci贸n
df_clima_aggregated = df_filtered_final.groupby(['latitud', 'longitud', 'Hacienda']).agg(
    T_Media=('temperatura', 'mean'),
    HR_Media=('humedad_relativa', 'mean'),
    P_Suma=('precipitacion', 'sum'),
    T_Std=('temperatura', 'std')
).reset_index()
df_corr = pd.merge(df_indicators, df_clima_aggregated, on=['latitud', 'longitud', 'Hacienda'], how='inner')

# 2. Verificaci贸n L贸gica (Requiere al menos dos puntos para variabilidad)
if len(selected_haciendas) < 2:
    st.warning("锔 **Advertencia de Correlaci贸n:** Selecciona **al menos dos ubicaciones** para calcular la Matriz de Correlaci贸n. La correlaci贸n requiere variabilidad espacial entre fincas.")
else:
    corr_vars = [selected_indicator_col, 'Altitud_m_s_n_m', 'T_Media', 'HR_Media', 'P_Suma', 'T_Std']
    corr_matrix = df_corr[corr_vars].corr()

    # 3. Graficar la Matriz
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(
        corr_matrix, 
        annot=True, 
        fmt=".2f", 
        cmap='coolwarm', 
        cbar_kws={'label': 'Coeficiente de Correlaci贸n'},
        ax=ax
    )
    plt.title(f'Matriz de Correlaci贸n con {selected_indicator_col}')
    st.pyplot(fig)

    # 4. Interpretaci贸n de la correlaci贸n con la Altitud
    alt_corr = corr_matrix.loc[selected_indicator_col, 'Altitud_m_s_n_m']
    st.info(
        f" **Correlaci贸n con Altitud:** El coeficiente de correlaci贸n de **{selected_indicator_col}** con la Altitud es **{alt_corr:.2f}**."
        f" Esto es clave para determinar las zonas agroecol贸gicas de mayor o menor riesgo."
    )


# --- 5. MODELADO ESTADSTICO (Validaci贸n del Indicador) ---

st.divider()
st.header(" Validaci贸n del Indicador de Riesgo (Modelo Estad铆stico)")

if len(df_indicators) < 5:
    st.warning("Se necesitan **m谩s de 5 ubicaciones** seleccionadas para que el an谩lisis de regresi贸n sea estad铆sticamente estable.")
else:
    if selected_patogeno_name == 'Roya del caf茅 (NHF)':
        st.markdown("Se utiliza **Regresi贸n Log铆stica** para modelar la probabilidad de **Incidencia de Roya (Simulada)**.")
        result = run_logistic_regression(df_indicators)

        if isinstance(result, str):
            st.error(f"Error al ejecutar el modelo: {result}")
        else:
            col_m1, col_m2 = st.columns([1, 2])
            
            # Columna 1: Resumen del Modelo
            col_m1.subheader("Resumen del Modelo Log铆stico")
            col_m1.dataframe(pd.DataFrame({
                'M茅trica': ['Observaciones', 'Pseudo R-cuadrado', 'Log-Verosimilitud'],
                'Valor': [result.nobs, f"{result.prsquared:.3f}", f"{result.llf:.2f}"]
            }).set_index('M茅trica'))
            
            # Columna 2: Coeficientes e Interpretaci贸n
            coef_df = result.summary2().tables[1]
            coef_df = coef_df[['Coef.', 'Std.Err.', 'P>|z|']]
            coef_df.columns = ['Coeficiente', 'Error Est谩ndar', 'P-Valor']
            
            col_m2.subheader("Coeficientes del Modelo")
            col_m2.dataframe(coef_df, use_container_width=True)
            
            st.markdown("#### Interpretaci贸n Clave (Log铆stica)")
            p_nhf = coef_df.loc['NHF_Roya_Horas', 'P-Valor']
            coef_nhf = coef_df.loc['NHF_Roya_Horas', 'Coeficiente']
            st.info(f"**Riesgo Clim谩tico (NHF_Roya_Horas):** Coeficiente: **{coef_nhf:.3f}** | P-Valor: **{p_nhf:.3f}**.")
            st.info(f"**Altitud (Altitud_km):** Coeficiente: **{coef_df.loc['Altitud_km', 'Coeficiente']:.3f}** | P-Valor: **{coef_df.loc['Altitud_km', 'P-Valor']:.3f}**.")


    elif selected_patogeno_name == 'Broca del caf茅 (GD)':
        st.markdown("Se utiliza **Regresi贸n Binomial Negativa** para modelar el **Conteo de Brocas (Simulado)**.")
        result = run_negative_binomial(df_indicators)
        
        if isinstance(result, str):
            st.error(f"Error al ejecutar el modelo: {result}")
        else:
            col_m1, col_m2 = st.columns([1, 2])
            
            # Columna 1: Resumen del Modelo
            col_m1.subheader("Resumen del Modelo Binomial Negativo")
            col_m1.dataframe(pd.DataFrame({
                'M茅trica': ['Observaciones', 'Log-Verosimilitud', 'Alpha (Sobredispersi贸n)'],
                'Valor': [result.nobs, f"{result.llf:.2f}", f"{result.params.get('alpha', 0.0):.3f}"]
            }).set_index('M茅trica'))
            
            # Columna 2: Coeficientes e Interpretaci贸n
            coef_df = result.summary2().tables[1]
            coef_df = coef_df[['Coef.', 'Std.Err.', 'P>|z|']]
            coef_df.columns = ['Coeficiente', 'Error Est谩ndar', 'P-Valor']
            
            col_m2.subheader("Coeficientes del Modelo")
            col_m2.dataframe(coef_df, use_container_width=True)
            
            st.markdown("#### Interpretaci贸n Clave (Binomial Negativa)")
            
            # Interpretaci贸n de GD
            p_gd = coef_df.loc['GD_Broca_Acumulado', 'P-Valor']
            coef_gd = coef_df.loc['GD_Broca_Acumulado', 'Coeficiente']
            
            st.info(
                f"**Riesgo Clim谩tico (GD_Broca_Acumulado):** Coeficiente: **{coef_gd:.3f}** | P-Valor: **{p_gd:.3f}**.\n"
                f"Un coeficiente positivo indica que m谩s Grados-D铆a se asocian con un mayor conteo de la plaga."
            )
            
            p_alt = coef_df.loc['Altitud_km', 'P-Valor']
            coef_alt = coef_df.loc['Altitud_km', 'Coeficiente']
            st.info(
                f"**Altitud (Altitud_km):** Coeficiente: **{coef_alt:.3f}** | P-Valor: **{p_alt:.3f}**.\n"
                f"Un coeficiente negativo (t铆pico) significa que la Altitud reduce el conteo de la plaga."
            )
